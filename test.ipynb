{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flan.v2 import mixtures\n",
    "from flan.v2.templates import PATTERNS\n",
    "import seqio\n",
    "from dataloader import *\n",
    "from seqio import TaskRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset wiki_dialog not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- gref\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- siscore\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_nlg\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_bio\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_xnli\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: wiki_dialog -> wiki_bio\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39mtfds\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mwiki_dialog/OQ\u001b[39;49m\u001b[39m'\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, shuffle_files\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:315\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mif\u001b[39;00m builder_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m   builder_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 315\u001b[0m dbuilder \u001b[39m=\u001b[39m builder(name, data_dir\u001b[39m=\u001b[39;49mdata_dir, try_gcs\u001b[39m=\u001b[39;49mtry_gcs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbuilder_kwargs)\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m    317\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:169\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbuilder_kwargs)  \u001b[39m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[39mraise\u001b[39;00m not_found_error\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:149\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m# First check whether code exists or not\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m builder_cls(\u001b[39mstr\u001b[39;49m(name))\n\u001b[1;32m    150\u001b[0m \u001b[39mexcept\u001b[39;00m registered\u001b[39m.\u001b[39mDatasetNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    151\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Class not found\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:101\u001b[0m, in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m registered\u001b[39m.\u001b[39mDatasetNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 101\u001b[0m   _reraise_with_list_builders(e, name\u001b[39m=\u001b[39;49mds_name)\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:445\u001b[0m, in \u001b[0;36m_reraise_with_list_builders\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m close_matches:\n\u001b[1;32m    443\u001b[0m   error_string \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mDid you mean: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00mclose_matches[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 445\u001b[0m \u001b[39mraise\u001b[39;00m py_utils\u001b[39m.\u001b[39;49mreraise(e, suffix\u001b[39m=\u001b[39;49merror_string)\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:97\u001b[0m, in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot load \u001b[39m\u001b[39m{\u001b[39;00mds_name\u001b[39m}\u001b[39;00m\u001b[39m when community datasets are disabled\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m registered\u001b[39m.\u001b[39;49mimported_builder_cls(\u001b[39mstr\u001b[39;49m(ds_name))\n\u001b[1;32m     98\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m typing\u001b[39m.\u001b[39mcast(Type[dataset_builder\u001b[39m.\u001b[39mDatasetBuilder], \u001b[39mcls\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/registered.py:129\u001b[0m, in \u001b[0;36mimported_builder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m is an abstract class.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _DATASET_REGISTRY:\n\u001b[0;32m--> 129\u001b[0m   \u001b[39mraise\u001b[39;00m DatasetNotFoundError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m builder_cls \u001b[39m=\u001b[39m _DATASET_REGISTRY[name]\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_builder_available(builder_cls):\n",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset wiki_dialog not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- gref\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- siscore\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_nlg\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_bio\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_xnli\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: wiki_dialog -> wiki_bio\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "df =tfds.load('wiki_dialog/OQ', split='train', shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki_dialog_template_9_zero_shot\n",
      "wiki_dialog_template_0to10_zero_shot\n",
      "wiki_dialog_template_0to10_no_opt_zero_shot\n",
      "wiki_dialog_template_0to10_non_deter_opt_zero_shot\n",
      "wiki_dialog_input_inversion_template_9_zero_shot\n",
      "wiki_dialog_input_inversion_template_0to10_zero_shot\n",
      "wiki_dialog_input_inversion_template_0to10_no_opt_zero_shot\n",
      "wiki_dialog_input_inversion_template_0to10_non_deter_opt_zero_shot\n",
      "wiki_dialog_template_0\n",
      "wiki_dialog_template_0_five_shot\n",
      "wiki_dialog_template_1\n",
      "wiki_dialog_template_1_two_shot\n",
      "wiki_dialog_template_2\n",
      "wiki_dialog_template_2_one_shot\n",
      "wiki_dialog_template_mix\n",
      "wiki_dialog_template_mix_five_shot\n",
      "wiki_dialog_template_0to10\n",
      "wiki_dialog_template_0to10_x_shot\n",
      "wiki_dialog_template_0_no_opt\n",
      "wiki_dialog_template_0_no_opt_five_shot\n",
      "wiki_dialog_template_1_no_opt\n",
      "wiki_dialog_template_1_no_opt_two_shot\n",
      "wiki_dialog_template_2_no_opt\n",
      "wiki_dialog_template_2_no_opt_one_shot\n",
      "wiki_dialog_template_mix_no_opt\n",
      "wiki_dialog_template_mix_no_opt_five_shot\n",
      "wiki_dialog_template_0to10_no_opt\n",
      "wiki_dialog_template_0to10_no_opt_x_shot\n",
      "wiki_dialog_input_inversion_template_0\n",
      "wiki_dialog_input_inversion_template_0_five_shot\n",
      "wiki_dialog_input_inversion_template_1\n",
      "wiki_dialog_input_inversion_template_1_two_shot\n",
      "wiki_dialog_input_inversion_template_2\n",
      "wiki_dialog_input_inversion_template_2_one_shot\n",
      "wiki_dialog_input_inversion_template_mix\n",
      "wiki_dialog_input_inversion_template_mix_five_shot\n",
      "wiki_dialog_input_inversion_template_0to10\n",
      "wiki_dialog_input_inversion_template_0to10_x_shot\n",
      "wiki_dialog_input_inversion_template_0_no_opt\n",
      "wiki_dialog_input_inversion_template_0_no_opt_five_shot\n",
      "wiki_dialog_input_inversion_template_1_no_opt\n",
      "wiki_dialog_input_inversion_template_1_no_opt_two_shot\n",
      "wiki_dialog_input_inversion_template_2_no_opt\n",
      "wiki_dialog_input_inversion_template_2_no_opt_one_shot\n",
      "wiki_dialog_input_inversion_template_mix_no_opt\n",
      "wiki_dialog_input_inversion_template_mix_no_opt_five_shot\n",
      "wiki_dialog_input_inversion_template_0to10_no_opt\n",
      "wiki_dialog_input_inversion_template_0to10_no_opt_x_shot\n"
     ]
    }
   ],
   "source": [
    "tasks = TaskRegistry.names()\n",
    "\n",
    "for task in tasks:\n",
    "    if \"wiki_dia\" in task:\n",
    "        print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset wiki_dialog not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- gref\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- siscore\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_nlg\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_bio\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_xnli\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: wiki_dialog -> wiki_bio\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m seqio\u001b[39m.\u001b[39;49mget_mixture_or_task(\u001b[39m\"\u001b[39;49m\u001b[39mwiki_dialog_template_0to10_zero_shot\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mget_dataset(sequence_length\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39minputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m256\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtargets\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m256\u001b[39;49m}) \n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/seqio/dataset_providers.py:1041\u001b[0m, in \u001b[0;36mTask.get_dataset\u001b[0;34m(self, sequence_length, split, use_cached, shuffle, shuffle_buffer_size, seed, shard_info, num_epochs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m   ds \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mget_dataset(\n\u001b[1;32m   1039\u001b[0m       split\u001b[39m=\u001b[39msplit, shuffle\u001b[39m=\u001b[39mshuffle, seed\u001b[39m=\u001b[39mseed, shard_info\u001b[39m=\u001b[39mshard_info)\n\u001b[1;32m   1040\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1041\u001b[0m   ds \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mget_dataset(split\u001b[39m=\u001b[39;49msplit, shuffle\u001b[39m=\u001b[39;49mshuffle, seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m   1042\u001b[0m   ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mshard(shard_info\u001b[39m.\u001b[39mnum_shards, shard_info\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m ((use_cached \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_cached_stats(split)[\u001b[39m\"\u001b[39m\u001b[39mexamples\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m<\u001b[39m _MAX_EXAMPLES_TO_MEM_CACHE)\n\u001b[1;32m   1046\u001b[0m     \u001b[39mor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_input_examples(split) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_input_examples(split) \u001b[39m<\u001b[39m _MAX_EXAMPLES_TO_MEM_CACHE)):\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/seqio/dataset_providers.py:371\u001b[0m, in \u001b[0;36mTfdsDataSource.get_dataset\u001b[0;34m(self, split, shuffle, seed, shard_info)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataset\u001b[39m(\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    366\u001b[0m     split: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m     shard_info: Optional[ShardInfo] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    370\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset:\n\u001b[0;32m--> 371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtfds_dataset\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m    372\u001b[0m       split, shuffle_files\u001b[39m=\u001b[39;49mshuffle, seed\u001b[39m=\u001b[39;49mseed, shard_info\u001b[39m=\u001b[39;49mshard_info)\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/seqio/utils.py:130\u001b[0m, in \u001b[0;36mLazyTfdsLoader.load\u001b[0;34m(self, split, shuffle_files, seed, shard_info)\u001b[0m\n\u001b[1;32m    125\u001b[0m split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_split(split)\n\u001b[1;32m    126\u001b[0m input_context \u001b[39m=\u001b[39m (\n\u001b[1;32m    127\u001b[0m     tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mInputContext(\n\u001b[1;32m    128\u001b[0m         num_input_pipelines\u001b[39m=\u001b[39mshard_info\u001b[39m.\u001b[39mnum_shards,\n\u001b[1;32m    129\u001b[0m         input_pipeline_id\u001b[39m=\u001b[39mshard_info\u001b[39m.\u001b[39mindex) \u001b[39mif\u001b[39;00m shard_info \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 130\u001b[0m \u001b[39mreturn\u001b[39;00m tfds\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    132\u001b[0m     split\u001b[39m=\u001b[39;49msplit,\n\u001b[1;32m    133\u001b[0m     data_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_dir,\n\u001b[1;32m    134\u001b[0m     shuffle_files\u001b[39m=\u001b[39;49mshuffle_files,\n\u001b[1;32m    135\u001b[0m     download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    136\u001b[0m     try_gcs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    137\u001b[0m     read_config\u001b[39m=\u001b[39;49mtfds\u001b[39m.\u001b[39;49mReadConfig(\n\u001b[1;32m    138\u001b[0m         shuffle_seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    139\u001b[0m         skip_prefetch\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    140\u001b[0m         input_context\u001b[39m=\u001b[39;49minput_context\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:315\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mif\u001b[39;00m builder_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m   builder_kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 315\u001b[0m dbuilder \u001b[39m=\u001b[39m builder(name, data_dir\u001b[39m=\u001b[39;49mdata_dir, try_gcs\u001b[39m=\u001b[39;49mtry_gcs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbuilder_kwargs)\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m    317\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:169\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbuilder_kwargs)  \u001b[39m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[39mraise\u001b[39;00m not_found_error\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:149\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m# First check whether code exists or not\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m builder_cls(\u001b[39mstr\u001b[39;49m(name))\n\u001b[1;32m    150\u001b[0m \u001b[39mexcept\u001b[39;00m registered\u001b[39m.\u001b[39mDatasetNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    151\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# Class not found\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:101\u001b[0m, in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n\u001b[1;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m registered\u001b[39m.\u001b[39mDatasetNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 101\u001b[0m   _reraise_with_list_builders(e, name\u001b[39m=\u001b[39;49mds_name)\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:445\u001b[0m, in \u001b[0;36m_reraise_with_list_builders\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m close_matches:\n\u001b[1;32m    443\u001b[0m   error_string \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mDid you mean: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00mclose_matches[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 445\u001b[0m \u001b[39mraise\u001b[39;00m py_utils\u001b[39m.\u001b[39;49mreraise(e, suffix\u001b[39m=\u001b[39;49merror_string)\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/load.py:97\u001b[0m, in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot load \u001b[39m\u001b[39m{\u001b[39;00mds_name\u001b[39m}\u001b[39;00m\u001b[39m when community datasets are disabled\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m registered\u001b[39m.\u001b[39;49mimported_builder_cls(\u001b[39mstr\u001b[39;49m(ds_name))\n\u001b[1;32m     98\u001b[0m   \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m typing\u001b[39m.\u001b[39mcast(Type[dataset_builder\u001b[39m.\u001b[39mDatasetBuilder], \u001b[39mcls\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/flan/lib/python3.8/site-packages/tensorflow_datasets/core/registered.py:129\u001b[0m, in \u001b[0;36mimported_builder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m is an abstract class.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _DATASET_REGISTRY:\n\u001b[0;32m--> 129\u001b[0m   \u001b[39mraise\u001b[39;00m DatasetNotFoundError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m builder_cls \u001b[39m=\u001b[39m _DATASET_REGISTRY[name]\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_builder_available(builder_cls):\n",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset wiki_dialog not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- amazon_us_reviews\n\t- anli\n\t- arc\n\t- bair_robot_pushing_small\n\t- bccd\n\t- beans\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- blimp\n\t- bool_q\n\t- c4\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- common_voice\n\t- coqa\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- davis\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- div2k\n\t- dmlab\n\t- doc_nli\n\t- dolphin_number_word\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- food101\n\t- forest_fires\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glue\n\t- goemotions\n\t- gpt3\n\t- gref\n\t- groove\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- irc_disentanglement\n\t- iris\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- math_dataset\n\t- mctaco\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- protein_net\n\t- qa4mre\n\t- qasc\n\t- quac\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- robonet\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- scicite\n\t- scientific_papers\n\t- sentiment140\n\t- shapes3d\n\t- siscore\n\t- smallnorb\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoken_digit\n\t- squad\n\t- stanford_dogs\n\t- stanford_online_products\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- tao\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tiny_shakespeare\n\t- titanic\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- vctk\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_nlg\n\t- web_questions\n\t- wider_face\n\t- wiki40b\n\t- wiki_bio\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_xnli\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: wiki_dialog -> wiki_bio\n"
     ]
    }
   ],
   "source": [
    "dataset = seqio.get_mixture_or_task(\"wiki_dialog_template_0to10_zero_shot\").get_dataset(sequence_length={\"inputs\": 256, \"targets\": 256}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'background', 'context', 'question', 'answer', '_task_name', '_task_source', '_template_type', 'inputs_pretokenized', 'inputs', 'targets_pretokenized', 'targets'])\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
